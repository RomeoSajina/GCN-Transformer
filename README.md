# GCN-Transformer
Official repository for paper titled "GCN-Transformer: Multi-task Graph Convolutional Network and Transformer for Multi-person Pose Forecasting"

> Multi-person pose forecasting involves predicting the future body poses of multiple individuals over time, involving complex movement dynamics and interaction dependencies. Its relevance spans various fields, including computer vision, robotics, human-computer interaction, and surveillance. This paper introduces GCN-Transformer, a novel model for multi-person pose forecasting that leverages the integration of Graph Convolutional Network and Transformer architectures. We integrated novel loss terms during the training phase to incentivize the model to learn both interaction dependencies and joint trajectory. Additionally, we conducted an ablation study to analyze the effects of various model components. Through comprehensive evaluations on the SoMoF Benchmark and ExPI datasets, employing VIM and MPJPE, our findings consistently highlight the superior performance of GCN-Transformer over existing models. Furthermore, we introduce a novel pose forecasting evaluation metric called Final Joint Position And Trajectory Error (FJPTE), which comprehensively assesses both local movement dynamics and global movement errors by considering the final position and the trajectory leading up to it. Findings on all evaluation metrics underscore the potential of GCN-Transformer to advance multi-person pose forecasting, offering promising applications in diverse domains.

The code for this paper will be made available soon.

For inquiries, please contact rsajina@unipu.hr
